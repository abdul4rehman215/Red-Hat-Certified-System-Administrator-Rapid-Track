# ğŸ—„ Lab 39: Managing Storage with NFS and Ceph

---

## ğŸ¯ Objective

This lab focuses on implementing enterprise storage solutions using:

- NFS (Network File System) for shared file storage
- Ceph for distributed block storage
- Kubernetes integration with Persistent Volumes
- Storage troubleshooting and validation

By completing this lab, I gained hands-on experience configuring traditional file storage and modern distributed storage systems within a clustered environment.

---

## ğŸ–¥ Lab Environment

| Node      | Role |
|-----------|-------|
| server1   | NFS Server + Ceph Bootstrap + Kubernetes Master |
| server2   | NFS Client + Ceph Node |
| server3   | Ceph Node |
| server4   | Kubernetes Worker |

### ğŸŒ Network Configuration

- server1 â†’ 192.168.1.10  
- server2 â†’ 192.168.1.11  
- server3 â†’ 192.168.1.12  
- server4 â†’ 192.168.1.13  

---

## ğŸ“‚ Repository Structure

```

lab39-managing-storage-nfs-ceph/
â”‚
â”œâ”€â”€ README.md
â”œâ”€â”€ commands.sh
â”œâ”€â”€ output.txt
â”œâ”€â”€ interview_qna.md
â”œâ”€â”€ troubleshooting.md
â”‚
â”œâ”€â”€ k8s-manifests/
â”‚   â”œâ”€â”€ nfs-pv.yaml
â”‚   â”œâ”€â”€ nfs-pvc.yaml
â”‚   â”œâ”€â”€ nfs-deployment.yaml
â”‚   â”œâ”€â”€ ceph-storageclass.yaml
â”‚   â”œâ”€â”€ ceph-pvc.yaml
â”‚   â””â”€â”€ ceph-deployment.yaml
â”‚
â””â”€â”€ configs/
â””â”€â”€ exports.conf

```

---

## ğŸš€ Task Overview

### ğŸ”¹ Task 1: Configure NFS Server and Client
- Installed and configured NFS server
- Created export directories
- Configured `/etc/exports`
- Mounted NFS shares on client
- Enabled persistent mounting via `/etc/fstab`
- Validated file sharing across nodes

---

### ğŸ”¹ Task 2: Deploy Ceph Distributed Storage
- Installed Ceph components on 3 nodes
- Bootstrapped Ceph cluster
- Added OSDs (Object Storage Daemons)
- Created RBD storage pool
- Created and mapped block device
- Formatted and mounted Ceph block storage
- Validated write operations

---

### ğŸ”¹ Task 3: Integrate Storage with Kubernetes
- Created NFS Persistent Volume and PVC
- Deployed application using shared NFS storage
- Installed Ceph CSI driver
- Created Ceph StorageClass
- Provisioned dynamic Ceph PVC
- Deployed application using Ceph RBD storage
- Verified data persistence

---

## ğŸ”¥ What I Learned

- Difference between file storage (NFS) and block storage (Ceph)
- How distributed storage achieves scalability and redundancy
- Ceph cluster bootstrapping and OSD management
- Kubernetes Persistent Volume architecture
- CSI driver integration for dynamic provisioning
- Enterprise storage troubleshooting techniques

---

## ğŸ¢ Real-World Relevance

This lab simulates real enterprise environments where:

- Applications require persistent shared storage
- Kubernetes clusters need dynamic storage provisioning
- Storage must be scalable and highly available
- Hybrid cloud and on-prem infrastructures coexist

---

## ğŸ“Š Storage Comparison

| Feature        | NFS | Ceph |
|---------------|------|------|
| Storage Type  | File-based | Block-based |
| Access Mode   | RWX | RWO |
| Scalability   | Limited | Highly Scalable |
| Replication   | Manual | Built-in |
| Enterprise Use | Shared directories | Cloud-native infrastructure |

---

## ğŸ§  Why This Matters

Modern infrastructure depends heavily on reliable storage systems.  
Understanding both traditional NFS and distributed Ceph prepares me for:

- RHCSA / RHCE / OpenShift certifications
- Kubernetes administration roles
- DevOps & Cloud Engineering
- Enterprise Linux system administration

---

## âœ… Result

Successfully configured:

- Fully functional NFS shared storage
- 3-node Ceph distributed cluster
- Kubernetes integration with both storage backends
- Verified persistent data across workloads
